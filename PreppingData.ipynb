{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prepping\n",
    "\n",
    "The first thing to be done is to get the data in a format for Amazon Personalize.\n",
    "\n",
    "We are looking to supply Item Metadata and User-Item Interaction data. We are also only going to use data that is provided here, no additional metadata will be added at this time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import boto3\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data\n",
    "\n",
    "The data comes in 2 files, one with movie data and the other with user-movie interactions. Below we are going to describe the schema and the manipulations required to build CSV files for Personalize.\n",
    "\n",
    "### Movie Item Metadata:\n",
    "\n",
    "#### movie_titles.csv:\n",
    "\n",
    "* MovieID,\n",
    "* YearOfRelease\n",
    "* Title\n",
    "\n",
    "#### Personalize Required Data:\n",
    "\n",
    "* ITEM_ID = string\n",
    "\n",
    "#### Personalize Item Schema:\n",
    "\n",
    "Notice that we are removing the `Title` attribute, this provides metadata but there's no obvious reason for it to be useful for predicting a movie recommendation. It would be worth experimenting with this added or other metadata added later.\n",
    "\n",
    "* ITEM_ID = MovieID\n",
    "* Year_Of_Release = datetime\n",
    "\n",
    "\n",
    "### User - Movie Interaction Data:\n",
    "\n",
    "#### combined_data_1.txt ( 2, 3, 4 )\n",
    "\n",
    "* MovieID\n",
    "* * CustomerID\n",
    "* * Rating\n",
    "* * Date\n",
    "\n",
    "#### Personalize Required Data:\n",
    "\n",
    "* USER_ID\n",
    "* ITEM_ID\n",
    "* TIMESTAMP\n",
    "\n",
    "#### Personalize User-Item Interaction Schema:\n",
    "\n",
    "As per the movielens dataset we will be removing `Rating` from the dataset and mapping `Customer ID` to `USER_ID`, `Movie ID` to `ITEM_ID`, and `Date` will be converted to a unix epoch timestamp and represented as `TIMESTAMP`.\n",
    "\n",
    "Also we will reduce the interactions to only include ratings of 3 or greater just like the movielens data. This is to keep the experiments close in inputs but additional approaches could be valid.\n",
    "\n",
    "* USER_ID = string\n",
    "* ITEM_ID  = string\n",
    "* TIMESTAMP = long\n",
    "\n",
    "The last heavy change to the interaciton data will be combining the interaction files from 4 distinct text files into one larger CSV. This may require a larger notebook instance, in this case we are using a 2XL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepping Movie Data:\n",
    "\n",
    "The CSV is nearly in the right format, the process below will just rename the headers, generate a new CSV, and upload it to S3 for usage with Personalize.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell will take quite a few minutes to complete, the following cells will append the other content to the CSV\n",
    "\n",
    "# First create the interactions CSV File\n",
    "with open('items.csv', 'w') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "    \n",
    "    # Write the headers:\n",
    "    filewriter.writerow(['ITEM_ID', 'YEAR_OF_RELEASE'])\n",
    "    # Next open the first items file\n",
    "    with open('netflix-prize-data/movie_titles.csv', encoding = \"ISO-8859-1\") as fileHandler:\n",
    "        for line in fileHandler:\n",
    "            # Clean and parse the line\n",
    "            line = line.strip('\\n').split(',')\n",
    "            filewriter.writerow([line[0], line[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncreate_schema_response = personalize.create_schema(\\n    name = \"django-items-schema-finalF\",\\n    schema = json.dumps(item_schema)\\n)\\n\\nschema_arn = create_schema_response[\\'schemaArn\\']\\nprint(json.dumps(create_schema_response, indent=2))\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Item Schema Cell\n",
    "item_schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Item\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"ITEM_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"YEAR_OF_RELEASE\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "create_schema_response = personalize.create_schema(\n",
    "    name = \"django-items-schema-finalF\",\n",
    "    schema = json.dumps(item_schema)\n",
    ")\n",
    "\n",
    "schema_arn = create_schema_response['schemaArn']\n",
    "print(json.dumps(create_schema_response, indent=2))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepping User Movie Interaction Data\n",
    "\n",
    "Here things get a lot more complicated, the files are pretty large each around 500MB, also they are not structured in a CSV format so we need to build a parser for the file to build a dataframe, and then to export the dataframe to a CSV that is shipped to S3. Just like the Movie metadata, there is a JSON file in the project that is the schema that can be used to build the dataset items within Personalize.\n",
    "\n",
    "Basic Algo:\n",
    "\n",
    "1. Loop through the file, on finding a number that also contains a `:` character\n",
    "1. Identify the number,\n",
    "1. Until a new number is found split the file into components of `CustomerID`, `Rating`, `Date`.\n",
    "1. Convert the date to a unix epoch format\n",
    "1. Add line to dataframe or temp storage device\n",
    "1. Export to CSV with correct headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The functions below will aid in decontsructing the interaction data into \n",
    "# a usable CSV\n",
    "\n",
    "def strip_line(line):\n",
    "    \"\"\"\n",
    "    As bad characters are found in this experiment, they will be\n",
    "    added here so they are removed from the dataset, for example tabs or new lines.\n",
    "    \"\"\"\n",
    "    line = line.strip('\\n')\n",
    "    return line\n",
    "\n",
    "\n",
    "def is_line_a_movie(line):\n",
    "    \"\"\"\n",
    "    This will take in a string `line` and determine if it has the \n",
    "    characteristics of being a movie or not.\n",
    "    \n",
    "    Movie lines do not contain commas, so we will split on those,\n",
    "    get the length of the array, and determine if it is a user or not.\n",
    "    \"\"\"\n",
    "    line_list = line.split(',')\n",
    "    if len(line_list) == 1:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_line_an_interaction(line):\n",
    "    \"\"\"\n",
    "    This will take in a string `line` and determine if it has the\n",
    "    characteristics of an interaction or not.\n",
    "    \n",
    "    Interaction lines are identified by containing commas and an list\n",
    "    length of 3, if those conditions are met true is returned, otherwise false\n",
    "    \"\"\"\n",
    "    line_list = line.split(',')\n",
    "    if len(line_list) == 3:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def convert_date_to_epoch(date_str):\n",
    "    \"\"\"\n",
    "    The Netflix dataset provides dates like `2005-09-06` to designate:\n",
    "    * Year 2005\n",
    "    * Month September / 9 \n",
    "    * Day 6\n",
    "    \n",
    "    We need these in unix epoch format, the code below does that and returns\n",
    "    the date as an epoch\n",
    "    \"\"\"\n",
    "    format = '%Y-%m-%d'\n",
    "    epoch = time.mktime(time.strptime(date_str, format))\n",
    "    epoch = int(epoch)\n",
    "    return epoch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell will take quite a few minutes to complete, the following cells will append the other content to the CSV\n",
    "\n",
    "# First create the interactions CSV File\n",
    "with open('interactions.csv', 'w') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "    # Next open the first interactions file\n",
    "    with open('netflix-prize-data/combined_data_1.txt') as fileHandler:\n",
    "        movie = 0 \n",
    "        # First write the headers for the file:\n",
    "        filewriter.writerow(['USER_ID', 'ITEM_ID', 'TIMESTAMP'])\n",
    "        # Read Each Line in a Loop:\n",
    "        for line in fileHandler:\n",
    "            line = strip_line(line=line)\n",
    "            # Now we determine if it is a movie:\n",
    "            if is_line_a_movie(line=line):\n",
    "                movie = line.split(',')[0].strip(':')\n",
    "            # If the line is an interaction\n",
    "            elif is_line_an_interaction(line=line):\n",
    "                line = line.split(',')\n",
    "                if int(line[1]) >= 3:\n",
    "                    timestamp = convert_date_to_epoch(date_str=line[2])\n",
    "                    # Once all values are sorted write the row\n",
    "                    filewriter.writerow([line[0], str(movie), str(timestamp)])\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Note here we append file 2\\nwith open('interactions.csv', 'a') as csvfile:\\n    filewriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\\n    \\n    # Next open the first interactions file\\n    with open('netflix-prize-data/combined_data_2.txt') as fileHandler:\\n        movie = 0 \\n        # Read Each Line in a Loop:\\n        for line in fileHandler:\\n            line = strip_line(line=line)\\n            # Now we determine if it is a movie:\\n            if is_line_a_movie(line=line):\\n                movie = line.split(',')[0].strip(':')\\n            # If the line is an interaction\\n            elif is_line_an_interaction(line=line):\\n                line = line.split(',')\\n                if int(line[1]) >= 3:\\n                    timestamp = convert_date_to_epoch(date_str=line[2])\\n                    # Once all values are sorted write the row\\n                    filewriter.writerow([line[0], str(movie), str(timestamp)])\\n\\n\\n# Note here we append file 3\\nwith open('interactions.csv', 'a') as csvfile:\\n    filewriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\\n    \\n    # Next open the first interactions file\\n    with open('netflix-prize-data/combined_data_3.txt') as fileHandler:\\n        movie = 0 \\n        # Read Each Line in a Loop:\\n        for line in fileHandler:\\n            line = strip_line(line=line)\\n            # Now we determine if it is a movie:\\n            if is_line_a_movie(line=line):\\n                movie = line.split(',')[0].strip(':')\\n            # If the line is an interaction\\n            elif is_line_an_interaction(line=line):\\n                line = line.split(',')\\n                if int(line[1]) >= 3:\\n                    timestamp = convert_date_to_epoch(date_str=line[2])\\n                    # Once all values are sorted write the row\\n                    filewriter.writerow([line[0], str(movie), str(timestamp)])\\n\\n\\n\\n# Note here we append file 4\\nwith open('interactions.csv', 'a') as csvfile:\\n    filewriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\\n    \\n    # Next open the first interactions file\\n    with open('netflix-prize-data/combined_data_2.txt') as fileHandler:\\n        movie = 0 \\n        # Read Each Line in a Loop:\\n        for line in fileHandler:\\n            line = strip_line(line=line)\\n            # Now we determine if it is a movie:\\n            if is_line_a_movie(line=line):\\n                movie = line.split(',')[0].strip(':')\\n            # If the line is an interaction\\n            elif is_line_an_interaction(line=line):\\n                line = line.split(',')\\n                if int(line[1]) >= 3:\\n                    timestamp = convert_date_to_epoch(date_str=line[2])\\n                    # Once all values are sorted write the row\\n                    filewriter.writerow([line[0], str(movie), str(timestamp)])\\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Note here we append file 2\n",
    "with open('interactions.csv', 'a') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "    # Next open the first interactions file\n",
    "    with open('netflix-prize-data/combined_data_2.txt') as fileHandler:\n",
    "        movie = 0 \n",
    "        # Read Each Line in a Loop:\n",
    "        for line in fileHandler:\n",
    "            line = strip_line(line=line)\n",
    "            # Now we determine if it is a movie:\n",
    "            if is_line_a_movie(line=line):\n",
    "                movie = line.split(',')[0].strip(':')\n",
    "            # If the line is an interaction\n",
    "            elif is_line_an_interaction(line=line):\n",
    "                line = line.split(',')\n",
    "                if int(line[1]) >= 3:\n",
    "                    timestamp = convert_date_to_epoch(date_str=line[2])\n",
    "                    # Once all values are sorted write the row\n",
    "                    filewriter.writerow([line[0], str(movie), str(timestamp)])\n",
    "\n",
    "\n",
    "# Note here we append file 3\n",
    "with open('interactions.csv', 'a') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "    # Next open the first interactions file\n",
    "    with open('netflix-prize-data/combined_data_3.txt') as fileHandler:\n",
    "        movie = 0 \n",
    "        # Read Each Line in a Loop:\n",
    "        for line in fileHandler:\n",
    "            line = strip_line(line=line)\n",
    "            # Now we determine if it is a movie:\n",
    "            if is_line_a_movie(line=line):\n",
    "                movie = line.split(',')[0].strip(':')\n",
    "            # If the line is an interaction\n",
    "            elif is_line_an_interaction(line=line):\n",
    "                line = line.split(',')\n",
    "                if int(line[1]) >= 3:\n",
    "                    timestamp = convert_date_to_epoch(date_str=line[2])\n",
    "                    # Once all values are sorted write the row\n",
    "                    filewriter.writerow([line[0], str(movie), str(timestamp)])\n",
    "\n",
    "\n",
    "\n",
    "# Note here we append file 4\n",
    "with open('interactions.csv', 'a') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "    # Next open the first interactions file\n",
    "    with open('netflix-prize-data/combined_data_2.txt') as fileHandler:\n",
    "        movie = 0 \n",
    "        # Read Each Line in a Loop:\n",
    "        for line in fileHandler:\n",
    "            line = strip_line(line=line)\n",
    "            # Now we determine if it is a movie:\n",
    "            if is_line_a_movie(line=line):\n",
    "                movie = line.split(',')[0].strip(':')\n",
    "            # If the line is an interaction\n",
    "            elif is_line_an_interaction(line=line):\n",
    "                line = line.split(',')\n",
    "                if int(line[1]) >= 3:\n",
    "                    timestamp = convert_date_to_epoch(date_str=line[2])\n",
    "                    # Once all values are sorted write the row\n",
    "                    filewriter.writerow([line[0], str(movie), str(timestamp)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading Interactions Data\n",
    "\n",
    "Now that the CSV above has been created it needs to be uploaded to s3 so that it can be used with Amazon Personalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
